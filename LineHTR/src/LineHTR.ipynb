{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LineHTR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YTMb0ZWUEdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a902282-a3a0-4cd2-bcfe-49db68d2b7e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgooPUhXUFvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3817992c-57a7-48fc-fc12-6ef785f8317c"
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "import codecs\n",
        "import sys\n",
        "\n",
        "from skimage.filters import threshold_local, threshold_yen\n",
        "import argparse\n",
        "import editdistance\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjRYLg8iUjfZ",
        "colab_type": "text"
      },
      "source": [
        "## helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCj_-zTLUMzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SMALL_HEIGHT = 800"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqto56NzUOYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(imgPath, imgSize, binary=True):\n",
        "    \"\"\" Pre-processing image for predicting \"\"\"\n",
        "    img = cv2.imread(imgPath)\n",
        "    # Binary\n",
        "    if binary:\n",
        "        brightness = 0\n",
        "        contrast = 50\n",
        "        img = np.int16(img)\n",
        "        img = img * (contrast/127+1) - contrast + brightness\n",
        "        img = np.clip(img, 0, 255)\n",
        "        img = np.uint8(img)\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        T = threshold_local(img, 11, offset=10, method=\"gaussian\")\n",
        "        img = (img > T).astype(\"uint8\") * 255\n",
        "\n",
        "        # Increase line width\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        img = cv2.erode(img, kernel, iterations=1)\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create target image and copy sample image into it\n",
        "    (wt, ht) = imgSize\n",
        "    (h, w) = img.shape\n",
        "    fx = w / wt\n",
        "    fy = h / ht\n",
        "    f = max(fx, fy)\n",
        "\n",
        "    # Scale according to f (result at least 1 and at most wt or ht)\n",
        "    newSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1))\n",
        "    img = cv2.resize(img, newSize)\n",
        "    target = np.ones([ht, wt]) * 255\n",
        "    target[0:newSize[1], 0:newSize[0]] = img\n",
        "\n",
        "    # Transpose for TF\n",
        "    img = cv2.transpose(target)\n",
        "\n",
        "    # Normalize\n",
        "    (m, s) = cv2.meanStdDev(img)\n",
        "    m = m[0][0]\n",
        "    s = s[0][0]\n",
        "    img = img - m\n",
        "    img = img / s if s > 0 else img\n",
        "\n",
        "    return img"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx82vI1tUQ-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wer(r, h):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance.\n",
        "\n",
        "    Works only for iterables up to 254 elements (uint8).\n",
        "    O(nm) time ans space complexity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    r : list\n",
        "    h : list\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
        "    1\n",
        "    >>> wer(\"who is there\".split(), \"\".split())\n",
        "    3\n",
        "    >>> wer(\"\".split(), \"who is there\".split())\n",
        "    3\n",
        "    \"\"\"\n",
        "    # initialisation\n",
        "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + 1\n",
        "                insertion = d[i][j-1] + 1\n",
        "                deletion = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "    return d[len(r)][len(h)]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL77kSQzUmtS",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pAR1hM3UTFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FilePaths:\n",
        "    \"\"\" Filenames and paths to data \"\"\"\n",
        "    fnCharList = '/content/drive/My Drive/LineHTR/model/charList.txt'\n",
        "    fnWordCharList = '/content/drive/My Drive/LineHTR/model/wordCharList.txt'\n",
        "    fnCorpus = '/content/drive/My Drive/LineHTR/data/corpus.txt'\n",
        "    fnAccuracy = '/content/drive/My Drive/LineHTR/model/accuracy.txt'\n",
        "    fnTrain = '/content/drive/My Drive/LineHTR/data/'\n",
        "    fnInfer = '/content/drive/My Drive/LineHTR/data/a01-000u-00.png'  # 测试图片"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-6vJkxFUdiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sample:\n",
        "    \"\"\" Sample from the dataset \"\"\"\n",
        "\n",
        "    def __init__(self, gtText, filePath):\n",
        "        self.gtText = gtText\n",
        "        self.filePath = filePath"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bNcRMnKUfHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batch:\n",
        "    \"\"\" Batch containing images and ground truth texts \"\"\"\n",
        "\n",
        "    def __init__(self, gtTexts, imgs):\n",
        "        self.imgs = np.stack(imgs, axis=0)\n",
        "        self.gtTexts = gtTexts"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq9Qd0_XUqfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader:\n",
        "    \"\"\" Loads data from data folder \"\"\"\n",
        "\n",
        "    def __init__(self, filePath, batchSize, imgSize, maxTextLen):\n",
        "        \"\"\" Loader for dataset at given location, preprocess images and text according to parameters \"\"\"\n",
        "\n",
        "        assert filePath[-1] == '/'\n",
        "\n",
        "        self.currIdx = 0\n",
        "        self.batchSize = batchSize\n",
        "        self.imgSize = imgSize\n",
        "        self.samples = []\n",
        "\n",
        "        chars = set()\n",
        "        bad_samples = []\n",
        "        # Read json lables file\n",
        "        # Dataset folder should contain a labels.json file inside, with key is the file name of images and value is the label\n",
        "        with open(filePath + 'test.txt', 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                if not line or line[0] == '#':\n",
        "                    continue\n",
        "\n",
        "                lineSplit = line.strip().split(' ')\n",
        "                assert len(lineSplit) >= 9\n",
        "\n",
        "                # filename: part1-part2-part3 --> part1/part1-part2/part1-part2-part3.png\n",
        "                fileNameSplit = lineSplit[0].split('-')\n",
        "                fileName = filePath + 'lines/' + fileNameSplit[0] + '/' + fileNameSplit[0] + '-' + fileNameSplit[1] + '/' + lineSplit[0] + '.png'\n",
        "\n",
        "                # GT text are columns starting at 9\n",
        "                gtText = self.truncateLabel(' '.join(lineSplit[8:]), maxTextLen)\n",
        "                chars = chars.union(set(list(gtText)))\n",
        "\n",
        "                # check if image is not empty\n",
        "                if not os.path.getsize(fileName):\n",
        "                    bad_samples.append(lineSplit[0] + '.png')\n",
        "                    continue\n",
        "\n",
        "                # put sample into list\n",
        "                self.samples.append(Sample(gtText, fileName))\n",
        "\n",
        "        self.charList = list(open(FilePaths.fnCharList).read())\n",
        "\n",
        "        # Split into training and validation set: 90% - 10%\n",
        "        splitIdx = int(0.95 * len(self.samples))\n",
        "        self.trainSamples = self.samples[:splitIdx]\n",
        "        self.validationSamples = self.samples[splitIdx:]\n",
        "\n",
        "        print(\"Train on\", len(self.trainSamples), \"images. Validate on\",\n",
        "              len(self.validationSamples), \"images.\")\n",
        "\n",
        "        # Number of randomly chosen samples per epoch for training\n",
        "        self.numTrainSamplesPerEpoch = 5500\n",
        "\n",
        "        # Start with train set\n",
        "        self.trainSet()\n",
        "\n",
        "        # List of all chars in dataset\n",
        "        #self.charList = sorted(list(chars))\n",
        "\n",
        "    def truncateLabel(self, text, maxTextLen):\n",
        "        # ctc_loss can't compute loss if it cannot find a mapping between text label and input\n",
        "        # labels. Repeat letters cost double because of the blank symbol needing to be inserted.\n",
        "        # If a too-long label is provided, ctc_loss returns an infinite gradient\n",
        "        cost = 0\n",
        "        for i in range(len(text)):\n",
        "            if i != 0 and text[i] == text[i - 1]:\n",
        "                cost += 2\n",
        "            else:\n",
        "                cost += 1\n",
        "            if cost > maxTextLen:\n",
        "                return text[:i]\n",
        "        return text\n",
        "\n",
        "    def trainSet(self):\n",
        "        \"\"\" Switch to randomly chosen subset of training set \"\"\"\n",
        "        self.currIdx = 0\n",
        "        random.shuffle(self.trainSamples)\n",
        "        self.samples = self.trainSamples[:self.numTrainSamplesPerEpoch]\n",
        "\n",
        "    def validationSet(self):\n",
        "        \"\"\" Switch to validation set \"\"\"\n",
        "        self.currIdx = 0\n",
        "        self.samples = self.validationSamples\n",
        "\n",
        "    def getIteratorInfo(self):\n",
        "        \"\"\" Current batch index and overall number of batches \"\"\"\n",
        "        return (self.currIdx // self.batchSize + 1, len(self.samples) // self.batchSize)\n",
        "\n",
        "    def hasNext(self):\n",
        "        \"\"\" Iterator \"\"\"\n",
        "        return self.currIdx + self.batchSize <= len(self.samples)\n",
        "\n",
        "    def getNext(self):\n",
        "        \"\"\" Iterator \"\"\"\n",
        "        batchRange = range(self.currIdx, self.currIdx + self.batchSize)\n",
        "        gtTexts = [self.samples[i].gtText for i in batchRange]\n",
        "        imgs = [preprocessor(self.samples[i].filePath,\n",
        "                             self.imgSize, binary=True) for i in batchRange]\n",
        "        self.currIdx += self.batchSize\n",
        "        return Batch(gtTexts, imgs)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cusv9rzmVBL6",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_012NCWVU0rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderType:\n",
        "    BestPath = 0\n",
        "    WordBeamSearch = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TFxmXZPVDh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "    # Model Constants\n",
        "    batchSize = 50\n",
        "    imgSize = (800, 64)\n",
        "    maxTextLen = 100\n",
        "\n",
        "\n",
        "    def __init__(self, charList, decoderType=DecoderType.BestPath, mustRestore=False):\n",
        "        self.charList = charList\n",
        "        self.decoderType = decoderType\n",
        "        self.mustRestore = mustRestore\n",
        "        self.snapID = 0\n",
        "\n",
        "        # CNN\n",
        "        with tf.name_scope('CNN'):\n",
        "            with tf.name_scope('Input'):\n",
        "                self.inputImgs = tf.placeholder(tf.float32, shape=(Model.batchSize, Model.imgSize[0], Model.imgSize[1]))\n",
        "            cnnOut4d = self.setupCNN(self.inputImgs)\n",
        "\n",
        "        # RNN\n",
        "        with tf.name_scope('RNN'):\n",
        "            rnnOut3d = self.setupRNN(cnnOut4d)\n",
        "\n",
        "        # # Debuging CTC\n",
        "        # self.rnnOutput = tf.transpose(rnnOut3d, [1, 0, 2])\n",
        "\n",
        "        # CTC\n",
        "        with tf.name_scope('CTC'):\n",
        "            (self.loss, self.decoder) = self.setupCTC(rnnOut3d)\n",
        "            self.training_loss_summary = tf.summary.scalar(\n",
        "                'loss', self.loss)  # Tensorboard: Track loss\n",
        "\n",
        "        # Optimize NN parameters\n",
        "        with tf.name_scope('Optimizer'):\n",
        "            self.batchesTrained = 0\n",
        "            self.learningRate = tf.placeholder(tf.float32, shape=[])\n",
        "            self.optimizer = tf.train.RMSPropOptimizer(\n",
        "                self.learningRate).minimize(self.loss)\n",
        "\n",
        "        # Initialize TensorFlow\n",
        "        (self.sess, self.saver) = self.setupTF()\n",
        "\n",
        "        self.writer = tf.summary.FileWriter(\n",
        "            '/content/drive/My Drive/LineHTR/src/logs', self.sess.graph)  # Tensorboard: Create writer\n",
        "        self.merge = tf.summary.merge(\n",
        "            [self.training_loss_summary])  # Tensorboard: Merge\n",
        "\n",
        "\n",
        "    def setupCNN(self, cnnIn3d):\n",
        "        \"\"\" Create CNN layers and return output of these layers \"\"\"\n",
        "\n",
        "        cnnIn4d = tf.expand_dims(input=cnnIn3d, axis=3)\n",
        "\n",
        "        # First Layer: Conv (5x5) + Pool (2x2) - Output size: 400 x 32 x 64\n",
        "        with tf.name_scope('Conv_Pool_1'):\n",
        "            kernel = tf.Variable(\n",
        "                tf.truncated_normal([5, 5, 1, 64], stddev=0.1))\n",
        "            conv = tf.nn.conv2d(\n",
        "                cnnIn4d, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            relu = tf.nn.relu(conv)\n",
        "            pool = tf.nn.max_pool(relu, (1, 2, 2, 1), (1, 2, 2, 1), 'VALID')\n",
        "\n",
        "        # Second Layer: Conv (5x5) - Output size: 400 x 32 x 128\n",
        "        with tf.name_scope('Conv_2'):\n",
        "            kernel = tf.Variable(tf.truncated_normal(\n",
        "                [5, 5, 64, 128], stddev=0.1))\n",
        "            conv = tf.nn.conv2d(\n",
        "                pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            relu = tf.nn.relu(conv)\n",
        "\n",
        "        # Third Layer: Conv (3x3) + Pool (2x2) + Simple Batch Norm - Output size: 200 x 16 x 128\n",
        "        with tf.name_scope('Conv_Pool_BN_3'):\n",
        "            kernel = tf.Variable(tf.truncated_normal(\n",
        "                [3, 3, 128, 128], stddev=0.1))\n",
        "            conv = tf.nn.conv2d(\n",
        "                relu, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            mean, variance = tf.nn.moments(conv, axes=[0])\n",
        "            batch_norm = tf.nn.batch_normalization(\n",
        "                conv, mean, variance, offset=None, scale=None, variance_epsilon=0.001)\n",
        "            relu = tf.nn.relu(batch_norm)\n",
        "            pool = tf.nn.max_pool(relu, (1, 2, 2, 1), (1, 2, 2, 1), 'VALID')\n",
        "\n",
        "        # Fourth Layer: Conv (3x3) - Output size: 200 x 16 x 256\n",
        "        with tf.name_scope('Conv_4'):\n",
        "            kernel = tf.Variable(tf.truncated_normal(\n",
        "                [3, 3, 128, 256], stddev=0.1))\n",
        "            conv = tf.nn.conv2d(\n",
        "                pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            relu = tf.nn.relu(conv)\n",
        "\n",
        "        # Fifth Layer: Conv (3x3) - Output size: 200 x 16 x 256\n",
        "        with tf.name_scope('Conv_5'):\n",
        "            kernel = tf.Variable(tf.truncated_normal(\n",
        "                [3, 3, 256, 256], stddev=0.1))\n",
        "            conv = tf.nn.conv2d(\n",
        "                relu, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            relu = tf.nn.relu(conv)\n",
        "\n",
        "        # Sixth Layer: Conv (3x3) + Simple Batch Norm - Output size: 200 x 16 x 512\n",
        "        with tf.name_scope('Conv_BN_6'):\n",
        "            kernel = tf.Variable(tf.truncated_normal(\n",
        "                [3, 3, 256, 512], stddev=0.1))\n",
        "            conv = tf.nn.conv2d(\n",
        "                relu, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            mean, variance = tf.nn.moments(conv, axes=[0])\n",
        "            batch_norm = tf.nn.batch_normalization(\n",
        "                conv, mean, variance, offset=None, scale=None, variance_epsilon=0.001)\n",
        "            relu = tf.nn.relu(batch_norm)\n",
        "\n",
        "        # Seventh Layer: Conv (3x3) + Pool (2x2) - Output size: 100 x 8 x 512\n",
        "        with tf.name_scope('Conv_Pool_7'):\n",
        "            kernel = tf.Variable(tf.truncated_normal(\n",
        "                [3, 3, 512, 512], stddev=0.1))\n",
        "            conv = tf.nn.conv2d(\n",
        "                relu, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
        "            relu = tf.nn.relu(conv)\n",
        "            pool = tf.nn.max_pool(relu, (1, 2, 2, 1), (1, 2, 2, 1), 'VALID')\n",
        "\n",
        "        return pool\n",
        "\n",
        "\n",
        "    def setupRNN(self, rnnIn4d):\n",
        "        \"\"\" Create RNN layers and return output of these layers \"\"\"\n",
        "        rnnIn4d = tf.slice(rnnIn4d, [0, 0, 0, 0], [\n",
        "                           self.batchSize, 100, 1, 512])\n",
        "        rnnIn3d = tf.squeeze(rnnIn4d)\n",
        "\n",
        "        # 2 layers of LSTM cell used to build RNN\n",
        "        numHidden = 512\n",
        "        cells = [tf.nn.rnn_cell.LSTMCell(\n",
        "            numHidden, name='basic_lstm_cell') for _ in range(2)]\n",
        "        stacked = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
        "\n",
        "        # Bi-directional RNN\n",
        "        # BxTxF -> BxTx2H\n",
        "        ((forward, backward), _) = tf.nn.bidirectional_dynamic_rnn(\n",
        "            cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
        "\n",
        "        # BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n",
        "        concat = tf.expand_dims(tf.concat([forward, backward], 2), 2)\n",
        "\n",
        "        # Project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
        "        kernel = tf.Variable(tf.truncated_normal(\n",
        "            [1, 1, numHidden*2, len(self.charList)+1], stddev=0.1))\n",
        "        return tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
        "\n",
        "\n",
        "    def setupCTC(self, ctcIn3d):\n",
        "        \"\"\" Create CTC loss and decoder and return them \"\"\"\n",
        "        # BxTxC -> TxBxC\n",
        "        ctcIn3dTBC = tf.transpose(ctcIn3d, [1, 0, 2])\n",
        "\n",
        "        # Ground truth text as sparse tensor\n",
        "        with tf.name_scope('CTC_Loss'):\n",
        "            self.gtTexts = tf.SparseTensor(tf.placeholder(tf.int64, shape=[\n",
        "                                           None, 2]), tf.placeholder(tf.int32, [None]), tf.placeholder(tf.int64, [2]))\n",
        "            # Calculate loss for batch\n",
        "            self.seqLen = tf.placeholder(tf.int32, [None])\n",
        "            loss = tf.nn.ctc_loss(labels=self.gtTexts, inputs=ctcIn3dTBC, sequence_length=self.seqLen,\n",
        "                                  ctc_merge_repeated=True, ignore_longer_outputs_than_inputs=True)\n",
        "        with tf.name_scope('CTC_Decoder'):\n",
        "            # Decoder: Best path decoding or Word beam search decoding\n",
        "            if self.decoderType == DecoderType.BestPath:\n",
        "                decoder = tf.nn.ctc_greedy_decoder(\n",
        "                    inputs=ctcIn3dTBC, sequence_length=self.seqLen)\n",
        "            elif self.decoderType == DecoderType.WordBeamSearch:\n",
        "                # Import compiled word beam search operation (see https://github.com/githubharald/CTCWordBeamSearch)\n",
        "                word_beam_search_module = tf.load_op_library(\n",
        "                    '/content/drive/My Drive/LineHTR/src/TFWordBeamSearch.so')\n",
        "                \n",
        "                # Prepare: dictionary, characters in dataset, characters forming words\n",
        "                chars = codecs.open(FilePaths.fnCharList, 'r', 'utf8').read()\n",
        "                wordChars = codecs.open(\n",
        "                    FilePaths.fnWordCharList, 'r', 'utf8').read()\n",
        "                corpus = codecs.open(FilePaths.fnCorpus, 'r', 'utf8').read()\n",
        "\n",
        "                # # Decoder using the \"NGramsForecastAndSample\": restrict number of (possible) next words to at most 20 words: O(W) mode of word beam search\n",
        "                # decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(ctcIn3dTBC, dim=2), 25, 'NGramsForecastAndSample', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n",
        "\n",
        "                # Decoder using the \"Words\": only use dictionary, no scoring: O(1) mode of word beam search\n",
        "                decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(\n",
        "                    ctcIn3dTBC, dim=2), 25, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n",
        "\n",
        "        # Return a CTC operation to compute the loss and CTC operation to decode the RNN output\n",
        "        return (tf.reduce_mean(loss), decoder)\n",
        "\n",
        "\n",
        "    def setupTF(self):\n",
        "        \"\"\" Initialize TensorFlow \"\"\"\n",
        "        print('Python: ' + sys.version)\n",
        "        print('Tensorflow: ' + tf.__version__)\n",
        "        sess = tf.Session()  # Tensorflow session\n",
        "        saver = tf.train.Saver(max_to_keep=5)  # Saver saves model to file\n",
        "        modelDir = '/content/drive/My Drive/LineHTR/model/'\n",
        "        latestSnapshot = tf.train.latest_checkpoint(\n",
        "            modelDir)  # Is there a saved model?\n",
        "        # If model must be restored (for inference), there must be a snapshot\n",
        "        if self.mustRestore and not latestSnapshot:\n",
        "            raise Exception('No saved model found in: ' + modelDir)\n",
        "        # Load saved model if available\n",
        "        if latestSnapshot:\n",
        "            print('Init with stored values from ' + latestSnapshot)\n",
        "            saver.restore(sess, latestSnapshot)\n",
        "        else:\n",
        "            print('Init with new values')\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        return (sess, saver)\n",
        "\n",
        "    def toSpare(self, texts):\n",
        "        \"\"\" Convert ground truth texts into sparse tensor for ctc_loss \"\"\"\n",
        "        indices = []\n",
        "        values = []\n",
        "        shape = [len(texts), 0]  # Last entry must be max(labelList[i])\n",
        "        # Go over all texts\n",
        "        for (batchElement, texts) in enumerate(texts):\n",
        "            # Convert to string of label (i.e. class-ids)\n",
        "            # print(texts)\n",
        "            labelStr = []\n",
        "            for c in texts:\n",
        "                # print(c, '|', end='')\n",
        "                labelStr.append(self.charList.index(c))\n",
        "            # print(' ')\n",
        "            # labelStr = [self.charList.index(c) for c in texts]\n",
        "            # Sparse tensor must have size of max. label-string\n",
        "            if len(labelStr) > shape[1]:\n",
        "                shape[1] = len(labelStr)\n",
        "            # Put each label into sparse tensor\n",
        "            for (i, label) in enumerate(labelStr):\n",
        "                indices.append([batchElement, i])\n",
        "                values.append(label)\n",
        "\n",
        "        return (indices, values, shape)\n",
        "\n",
        "    def decoderOutputToText(self, ctcOutput):\n",
        "        \"\"\" Extract texts from output of CTC decoder \"\"\"\n",
        "        # Contains string of labels for each batch element\n",
        "        encodedLabelStrs = [[] for i in range(Model.batchSize)]\n",
        "        # Word beam search: label strings terminated by blank\n",
        "        if self.decoderType == DecoderType.WordBeamSearch:\n",
        "            blank = len(self.charList)\n",
        "            for b in range(Model.batchSize):\n",
        "                for label in ctcOutput[b]:\n",
        "                    if label == blank:\n",
        "                        break\n",
        "                    encodedLabelStrs[b].append(label)\n",
        "        # TF decoders: label strings are contained in sparse tensor\n",
        "        else:\n",
        "            # Ctc returns tuple, first element is SparseTensor\n",
        "            decoded = ctcOutput[0][0]\n",
        "            # Go over all indices and save mapping: batch -> values\n",
        "            #idxDict = {b : [] for b in range(Model.batchSize)}\n",
        "            for (idx, idx2d) in enumerate(decoded.indices):\n",
        "                label = decoded.values[idx]\n",
        "                batchElement = idx2d[0]  # index according to [b,t]\n",
        "                encodedLabelStrs[batchElement].append(label)\n",
        "        # Map labels to chars for all batch elements\n",
        "        return [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]\n",
        "\n",
        "    def trainBatch(self, batch, batchNum):\n",
        "        \"\"\" Feed a batch into the NN to train it \"\"\"\n",
        "        spare = self.toSpare(batch.gtTexts)\n",
        "        rate = 0.01 if self.batchesTrained < 50 else (\n",
        "            0.001 if self.batchesTrained < 2750 else 0.0001)\n",
        "        (loss_summary, _, lossVal) = self.sess.run([self.merge, self.optimizer, self.loss], {\n",
        "            self.inputImgs: batch.imgs, self.gtTexts: spare, self.seqLen: [Model.maxTextLen] * Model.batchSize, self.learningRate: rate})\n",
        "        # Tensorboard: Add loss_summary to writer\n",
        "        self.writer.add_summary(loss_summary, batchNum)\n",
        "        self.batchesTrained += 1\n",
        "        return lossVal\n",
        "\n",
        "    def inferBatch(self, batch):\n",
        "        \"\"\" Feed a batch into the NN to recognize texts \"\"\"\n",
        "        decoded = self.sess.run(self.decoder, {self.inputImgs: batch.imgs, self.seqLen: [\n",
        "                                Model.maxTextLen] * Model.batchSize})\n",
        "\n",
        "        # # Dump RNN output to .csv file\n",
        "        # decoded, rnnOutput = self.sess.run([self.decoder, self.rnnOutput], {\n",
        "        #                                    self.inputImgs: batch.imgs, self.seqLen: [Model.maxTextLen] * Model.batchSize})\n",
        "        # s = rnnOutput.shape\n",
        "        # b = 0\n",
        "        # csv = ''\n",
        "        # for t in range(s[0]):\n",
        "        #     for c in range(s[2]):\n",
        "        #         csv += str(rnnOutput[t, b, c]) + ';'\n",
        "        #     csv += '\\n'\n",
        "        # open('mat_0.csv', 'w').write(csv)\n",
        "\n",
        "        return self.decoderOutputToText(decoded)\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" Save model to file \"\"\"\n",
        "        self.snapID += 1\n",
        "        self.saver.save(self.sess, '/content/drive/My Drive/LineHTR/model/snapshot',\n",
        "                        global_step=self.snapID)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X86nfXblazYI",
        "colab_type": "text"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l2bVvz2YRMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Disable GPU\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsbhKMi1a_ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loader):\n",
        "    \"\"\" Train the neural network \"\"\"\n",
        "    epoch = 0  # Number of training epochs since start\n",
        "    bestCharErrorRate = float('inf')  # Best valdiation character error rate\n",
        "    noImprovementSince = 0  # Number of epochs no improvement of character error rate occured\n",
        "    earlyStopping = 8  # Stop training after this number of epochs without improvement\n",
        "    batchNum = 0\n",
        "\n",
        "    totalEpoch = len(loader.trainSamples)//loader.numTrainSamplesPerEpoch\n",
        "\n",
        "    while True:\n",
        "        epoch += 1\n",
        "        # print('Epoch:', epoch, '/', totalEpoch)\n",
        "        print('Epoch:', epoch)\n",
        "\n",
        "        # Train\n",
        "        print('Train neural network')\n",
        "        loader.trainSet()\n",
        "        while loader.hasNext():\n",
        "            batchNum += 1\n",
        "            iterInfo = loader.getIteratorInfo()\n",
        "            batch = loader.getNext()\n",
        "            loss = model.trainBatch(batch, batchNum)\n",
        "            print('Batch:', iterInfo[0], '/', iterInfo[1], 'Loss:', loss)\n",
        "\n",
        "        # Validate\n",
        "        charErrorRate, textLineAccuracy, wordErrorRate = validate(model, loader)\n",
        "        cer_summary = tf.Summary(value=[tf.Summary.Value(\n",
        "            tag='charErrorRate', simple_value=charErrorRate)])  # Tensorboard: Track charErrorRate\n",
        "        # Tensorboard: Add cer_summary to writer\n",
        "        model.writer.add_summary(cer_summary, epoch)\n",
        "        text_line_summary = tf.Summary(value=[tf.Summary.Value(\n",
        "            tag='textLineAccuracy', simple_value=textLineAccuracy)])  # Tensorboard: Track textLineAccuracy\n",
        "        # Tensorboard: Add text_line_summary to writer\n",
        "        model.writer.add_summary(text_line_summary, epoch)\n",
        "        wer_summary = tf.Summary(value=[tf.Summary.Value(\n",
        "            tag='wordErrorRate', simple_value=wordErrorRate)])  # Tensorboard: Track wordErrorRate\n",
        "        # Tensorboard: Add wer_summary to writer\n",
        "        model.writer.add_summary(wer_summary, epoch)\n",
        "\n",
        "        # If best validation accuracy so far, save model parameters\n",
        "        if charErrorRate < bestCharErrorRate:\n",
        "            print('Character error rate improved, save model')\n",
        "            bestCharErrorRate = charErrorRate\n",
        "            noImprovementSince = 0\n",
        "            model.save()\n",
        "            open(FilePaths.fnAccuracy, 'w').write(\n",
        "                'Validation character error rate of saved model: %f%%' % (charErrorRate*100.0))\n",
        "        else:\n",
        "            print('Character error rate not improved')\n",
        "            noImprovementSince += 1\n",
        "\n",
        "        # Stop training if no more improvement in the last x epochs\n",
        "        if noImprovementSince >= earlyStopping:\n",
        "            print('No more improvement since %d epochs. Training stopped.' %\n",
        "                  earlyStopping)\n",
        "            break"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGnXAp4Gbn-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, loader):\n",
        "    \"\"\" Validate neural network \"\"\"\n",
        "    print('Validate neural network')\n",
        "    loader.validationSet()\n",
        "    numCharErr = 0\n",
        "    numCharTotal = 0\n",
        "    numWordOK = 0\n",
        "    numWordTotal = 0\n",
        "\n",
        "    totalCER = []\n",
        "    totalWER = []\n",
        "    while loader.hasNext():\n",
        "        iterInfo = loader.getIteratorInfo()\n",
        "        print('Batch:', iterInfo[0], '/', iterInfo[1])\n",
        "        batch = loader.getNext()\n",
        "        recognized = model.inferBatch(batch)\n",
        "\n",
        "        print('Ground truth -> Recognized')\n",
        "        for i in range(len(recognized)):\n",
        "            numWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n",
        "            numWordTotal += 1\n",
        "            dist = editdistance.eval(recognized[i], batch.gtTexts[i])\n",
        "\n",
        "            currCER = dist/max(len(recognized[i]), len(batch.gtTexts[i]))\n",
        "            totalCER.append(currCER)\n",
        "\n",
        "            currWER = wer(recognized[i].split(), batch.gtTexts[i].split())\n",
        "            totalWER.append(currWER)\n",
        "\n",
        "            numCharErr += dist\n",
        "            numCharTotal += len(batch.gtTexts[i])\n",
        "            print('[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' +\n",
        "                  batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n",
        "\n",
        "    # Print validation result\n",
        "    try:\n",
        "        charErrorRate = sum(totalCER)/len(totalCER)\n",
        "        wordErrorRate = sum(totalWER)/len(totalWER)\n",
        "        textLineAccuracy = numWordOK / numWordTotal\n",
        "    except ZeroDivisionError:\n",
        "        charErrorRate = 0\n",
        "        wordErrorRate = 0\n",
        "        textLineAccuracy = 0\n",
        "    print('Character error rate: %f%%. Text line accuracy: %f%%. Word error rate: %f%%' %\n",
        "          (charErrorRate*100.0, textLineAccuracy*100.0, wordErrorRate*100.0))\n",
        "    return charErrorRate, textLineAccuracy, wordErrorRate\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkNZRvzibpYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(model, fnImg):\n",
        "    \"\"\" Recognize text in image provided by file path \"\"\"\n",
        "    img = preprocessor(fnImg, model.imgSize, binary=True)\n",
        "    # Fill all batch elements with same input image\n",
        "    batch = Batch(None, [img] * Model.batchSize)\n",
        "    recognized = model.inferBatch(batch)  # recognize text\n",
        "    # All batch elements hold same result\n",
        "    print('Recognized:', '\"' + recognized[0] + '\"')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AyY8iuCb0-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(operation):\n",
        "    \"\"\" Main function \"\"\"\n",
        "    decoderType = DecoderType.BestPath\n",
        "    # Load training data, create TF model\n",
        "    loader = DataLoader(FilePaths.fnTrain, Model.batchSize,Model.imgSize, Model.maxTextLen)\n",
        "\n",
        "    if operation == 'train':\n",
        "        # train\n",
        "        model = Model(loader.charList, decoderType)\n",
        "        train(model, loader)\n",
        "    elif operation == 'test':\n",
        "        # test\n",
        "        print(open(FilePaths.fnAccuracy).read())\n",
        "        model = Model(open(FilePaths.fnCharList).read(), decoderType, mustRestore=False)\n",
        "        infer(model, FilePaths.fnInfer)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct6yyvBTd_5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55pcS8i6lLzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}