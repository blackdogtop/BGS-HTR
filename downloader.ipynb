{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"downloader.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-gv6yKnnz9ZV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593439539248,"user_tz":-60,"elapsed":1490,"user":{"displayName":"富奕涵","photoUrl":"","userId":"11663353880113705153"}}},"source":["import requests,sys\n","from bs4 import BeautifulSoup\n","import os\n","from google.colab import drive\n","from urllib.request import urlopen"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"hy2J41mPNQ0A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593439557645,"user_tz":-60,"elapsed":19866,"user":{"displayName":"富奕涵","photoUrl":"","userId":"11663353880113705153"}},"outputId":"051e2acb-6b41-4729-c755-922a9c4d30c0"},"source":["drive.mount('/content/drive')\n","path = \"/content/drive/My Drive/MSc Project\"\n","os.chdir(path) #change directory to path"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xSGEzffvEJJS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593439557646,"user_tz":-60,"elapsed":19863,"user":{"displayName":"富奕涵","photoUrl":"","userId":"11663353880113705153"}}},"source":["class Downloader:\n","    \"\"\"\n","    类说明: download scanned borehole records images from BGS website\n","    :param\n","    :return\n","    Modify:\n","        18.05.2020\n","    \"\"\"\n","\n","\n","    def __init__(self):\n","        self.img_path = 'BGS_imgs' #where the imgs to store\n","        self.server_page = 'http://scans.bgs.ac.uk/sobi_scans/internal/boreholes/pages/'\n","        self.grids = {}            #store gird names and index    \n","\n","\n","    def download_img(self, url, filename):\n","        \"\"\"\n","        函数说明: download an image to the specific path\n","        :param url:the url of the image\n","        :param filename:filename of the img(contain path)\n","        :return none\n","        Modify:\n","            18.05.2020\n","        \"\"\"\n","        if not os.path.exists(self.img_path):\n","            os.mkdir(self.img_path)\n","        req = requests.get(url, stream=True)\n","        with open(filename,'wb') as f:\n","            for image in req.iter_content(chunk_size=1024):\n","                if image:\n","                    f.write(image)\n","                    f.flush\n","\n","\n","    def get_img_by_id(self, targets):\n","        \"\"\"\n","        函数说明: get all images of a BGS ID/Reference (a BGS ID/Reference probably has several imgs)\n","        :param\n","            target:scanned records of a BGS ID/Reference\n","        :return none\n","        Modify:\n","            08.06.2020 fix bug\n","        \"\"\"\n","        req = requests.get(url=targets)\n","        html = req.text\n","        div_bf = BeautifulSoup(html)\n","        div = div_bf.find_all('select', id='page')\n","        option_bf = BeautifulSoup(str(div))\n","        option = option_bf.find_all('option')\n","        for value in option:\n","            img_target = value.get('value')\n","            img_target = img_target+'.html' #添加后缀以免直接解析\n","            req_id = requests.get(url=img_target)\n","            html_id = req_id.text\n","            # print(html_id)\n","            img_bf = BeautifulSoup(html_id)\n","            img = img_bf.find_all('img',id='image')\n","            try:\n","                img_src = [i.get('src') for i in img][0]\n","                # print(img_src)\n","            except IndexError: #Image Unavailable\n","                continue\n","            else:\n","                img_id = img_src.split('/')[-3] + '_'\n","                img_name = img_src.split('/')[-1]\n","                filename = '{}{}{}'.format(self.img_path+'/', img_id, img_name)\n","                self.download_img(img_src, filename)\n","\n","\n","    def get_img_by_page(self, page):\n","        \"\"\"\n","        函数说明: get all images in a page \n","        :param\n","            page: which page to download\n","        :return\n","        Modify:\n","            08.06.2020 - fix bug\n","        \"\"\"\n","        url = self.server_page + str(page)\n","        html = requests.get(url, timeout=(3,20)).text #connect timeout, read timeout\n","        li_bf = BeautifulSoup(html)\n","        li = li_bf.find_all('li')\n","        a_bf = BeautifulSoup(str(li))\n","        a = a_bf.find_all('a')\n","        print(('Downloading The {} Page Images............').format(page))\n","        for i,each in enumerate(a):\n","            print(('Downloading the {} Record In The Page').format(i))\n","            target_url = each.get('href')\n","            target_url = target_url+'.html' #添加后缀以免直接解析\n","            # print(target_url)\n","            self.get_img_by_id(target_url)\n","\n","\n","    def get_grid_name(self, page_num = int):\n","        \"\"\"\n","        函数说明: get the first grid name in a page\n","        :param\n","            page_num: the page number\n","        :return\n","            grid_name: the first grid name in the page\n","        Modify:\n","            19.05.2020\n","        \"\"\"\n","        page_url = self.server_page + str(page_num)\n","        html = requests.get(url=page_url).text\n","        li_bf = BeautifulSoup(html)\n","        li = li_bf.find_all('li')\n","        grid_name = li[0].string[:2]\n","\n","        return grid_name\n","\n","\n","    def get_grid_index(self, page_num = int):\n","        \"\"\"\n","        函数说明: get a district grid index\n","        :param\n","            page: the started page number\n","        :return\n","            index: the range(start page and end page) of a grid\n","        Modify:\n","            19.05.2020\n","        \"\"\"\n","        init_page = low_page = page_num\n","        val = self.get_grid_name(low_page)\n","\n","        high_page = low_page+100\n","        grid_name = self.get_grid_name(high_page)\n","\n","        while val == grid_name: #确定high_page的值确保high_page的li的grid name与val不同\n","            high_page += (high_page-low_page)\n","            grid_name = self.get_grid_name(high_page)\n","\n","        mid_page = (low_page + high_page) // 2\n","        mid_grid_name = self.get_grid_name(mid_page)\n","        next_page = mid_page + 1\n","        next_grid_name = self.get_grid_name(next_page)\n","        \n","        while low_page<=high_page and not (mid_grid_name==val and next_grid_name!=val):\n","            mid_page = (low_page + high_page) // 2\n","            mid_grid_name = self.get_grid_name(mid_page)\n","            next_page = mid_page + 1\n","            next_grid_name = self.get_grid_name(next_page)\n","            if next_grid_name == val:\n","                low_page = mid_page + 1\n","            elif mid_grid_name != val:\n","                high_page = mid_page - 1\n","\n","        index = [init_page,mid_page]\n","        return index\n","\n","\n","    def get_bgs_grids_index(self):\n","        \"\"\"\n","        函数说明: get all UK BGS grids {name : index}\n","        :param\n","        :return\n","        Midify:\n","            19.05.2020\n","        \"\"\"\n","        started_page = 1\n","        while started_page <= 18561: #not get north part of UK scanned records\n","            name = self.get_grid_name(started_page)\n","            index = self.get_grid_index(started_page)\n","            self.grids[name] = index\n","            started_page = index[-1] +1\n","            print(\"进度为{:.2f} %\".format((started_page/18561)*100))\n","    \n","\n","    def get_img_by_grid(self, grid = str):\n","        \"\"\"\n","        函数说明: get all images of a grid\n","        :param\n","            grid: the name of grid, such as \"SD\", \"SE\"\n","        :return\n","        Modify:\n","            19.05.2020\n","        \"\"\"\n","        print('Getting Borehole Records Index......')\n","        self.get_bgs_grids_index()\n","        # print(self.grids)\n","        try:\n","            grid_index = self.grids[grid]\n","        except KeyError:\n","            print('Error')\n","        else:\n","            for page in range(grid_index[0], grid_index[1]+1):\n","                print(\"进度为{:.2f} %\".format(((page-grid_index[0])/(grid_index[-1]-grid_index[0]))*100))\n","                self.get_img_by_page(page)\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pwS98o_GvZgM","colab_type":"text"},"source":["###BNG square\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/British_National_Grid.svg/800px-British_National_Grid.svg.png\" width=\"150\">\n","\n","Notice:Only BGS scanned records form **SD, SE, SH, SJ, SK, SM, SN, SO, SP, SS, ST, SU, SY, SZ, TA, TF, TG, TL, TM, TQ** are available."]},{"cell_type":"code","metadata":{"id":"y-LCxxZYlVoe","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    downloader = Downloader()\n","    # downloader.get_img_by_grid('SD')\n","\n","    for i in range(1500,1600):\n","        downloader.get_img_by_page(i)"],"execution_count":null,"outputs":[]}]}